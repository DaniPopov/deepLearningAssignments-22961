{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxhNJhEz5klVTTq7Xvc4Za",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaniPopov/deepLearningAssignments-22961/blob/main/1stAssignmentDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMN 11\n",
        "\n",
        "Student info: Daniel Popov, ID: 319038519\n",
        "\n"
      ],
      "metadata": {
        "id": "DAXV6GW605wL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "rLYnMkq11OQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor"
      ],
      "metadata": {
        "id": "bBu4lKgf1NVm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### סעיף א"
      ],
      "metadata": {
        "id": "6nCvvOHk1KEk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ay9IFq200Gw",
        "outputId": "75ef5ae3-6347-4e96-fd92-7e1b63c0b6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]]])\n"
          ]
        }
      ],
      "source": [
        "def new_expand_as(A: Tensor, B: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Expands tensor A to the shape of tensor B by prepending singleton dimensions and replicating elements as necessary,\n",
        "    serving as a custom version of PyTorch's expand_as function.\n",
        "\n",
        "   Args:\n",
        "        A (Tensor): The source tensor to be expanded.\n",
        "        B (Tensor): The target tensor whose shape A should match after expansion.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: A new tensor with the same data as A but expanded to the shape of B.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If A has more dimensions than B, or if A and B are not compatible for broadcasting.\n",
        "\n",
        "    Example:\n",
        "        >>> A = torch.arange(27).reshape(3,3,3)\n",
        "        >>> B = torch.arange(9).reshape(3,3)\n",
        "        >>> print(new_expand_as(B, A))\n",
        "        tensor([[[0, 1, 2],\n",
        "                 [3, 4, 5],\n",
        "                 [6, 7, 8]],\n",
        "\n",
        "                 [[0, 1, 2],\n",
        "                 [3, 4, 5],\n",
        "                 [6, 7, 8]],\n",
        "\n",
        "                 [[0, 1, 2],\n",
        "                 [3, 4, 5],\n",
        "                 [6, 7, 8]]])\n",
        "    \"\"\"\n",
        "    if A.dim() > B.dim():\n",
        "        raise RuntimeError(\"expand_as: The source tensor cannot have more dimensions than the target tensor.\")\n",
        "\n",
        "    # Ensure A has the same number of dimensions as B by prepending ones\n",
        "    while A.dim() < B.dim():\n",
        "          A  = A.unsqueeze(0)\n",
        "\n",
        "    # Reverse the shapes to start checking from the trailing dimensions\n",
        "    A_shape_reversed = A.shape[::-1]\n",
        "    B_shape_reversed = B.shape[::-1]\n",
        "\n",
        "    # Check for broadcast compatibility\n",
        "    for i in range(len(A_shape_reversed)):\n",
        "        if A_shape_reversed[i] != 1 and A_shape_reversed[i] != B_shape_reversed[i]:\n",
        "            raise RuntimeError(f\"expand_as: The size of the source tensor ({A.shape}) must match the size of the target tensor ({ B.shape}) at non-singleton dimension.\")\n",
        "\n",
        "    C = A.clone()\n",
        "    C_shape_reversed = C.shape[::-1]\n",
        "\n",
        "    for i in range(len(C_shape_reversed)):\n",
        "        if C.shape[i] ==  1 and C.shape[i] != B.shape[i]:\n",
        "          C = torch.cat([C] * B.shape[i], dim=i)\n",
        "\n",
        "    return  C\n",
        "\n",
        "# Usage\n",
        "A = torch.arange(27).reshape(3,3,3)\n",
        "B = torch.arange(9).reshape(3,3)\n",
        "print(new_expand_as(B, A))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### סעיף ב"
      ],
      "metadata": {
        "id": "IIAVpp5p1Trp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def broad_together(A: Tensor, B: Tensor) -> (bool, tuple):\n",
        "    \"\"\"\n",
        "    Checks if two tensors, A and B, can be broadcast together according to broadcasting rules.\n",
        "    It returns a tuple containing a boolean indicating whether the tensors are compatible\n",
        "    for broadcasting and, if true, the resulting shape after broadcasting.\n",
        "\n",
        "    Args:\n",
        "        A (Tensor): The first tensor.\n",
        "        B (Tensor): The second tensor.\n",
        "\n",
        "    Returns:\n",
        "        (bool, tuple): A tuple where the first element is a boolean indicating whether the tensors\n",
        "        can be broadcast together, and the second element is the resulting broadcast shape if they can,\n",
        "        otherwise None.\n",
        "\n",
        "    Example:\n",
        "        >>> A = torch.rand(3, 3, 3)\n",
        "        >>> B = torch.arange(9).reshape(3, 3)\n",
        "        >>> can_broadcast, broadcast_shape = broad_together(B, A)\n",
        "        >>> print(can_broadcast, broadcast_shape)\n",
        "        True (3, 3, 3)\n",
        "    \"\"\"\n",
        "    max_dim = max(A.dim(), B.dim())\n",
        "    # Adjust dimensions of A and B to match the higher dimensionality\n",
        "    while A.dim() < max_dim:\n",
        "        A = A.unsqueeze(0)  # Prepend dimensions to A\n",
        "    while B.dim() < max_dim:\n",
        "        B = B.unsqueeze(0)  # Prepend dimensions to B\n",
        "\n",
        "    boradcast_shape = []\n",
        "\n",
        "    for i,j in zip(A.shape, B.shape):\n",
        "      if i == j or i == 1 or j == 1:\n",
        "          boradcast_shape.append(max(i,j))\n",
        "      else:\n",
        "          return (False, None)\n",
        "\n",
        "    return (True, tuple(boradcast_shape))\n",
        "\n",
        "# Usage example\n",
        "A = torch.rand(3, 3, 3)\n",
        "B = torch.arange(9).reshape(3, 3)\n",
        "print(broad_together(B, A))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdbZU48B1VKG",
        "outputId": "b658a32a-0eb3-4e75-bea3-b4b9e1c2fe94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(True, (3, 3, 3))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### סעיף ג"
      ],
      "metadata": {
        "id": "8muuHkfS1XLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def new_broadcast_tensors(A: Tensor, B: Tensor) -> (Tensor, Tensor):\n",
        "    \"\"\"\n",
        "    Broadcasts two input tensors, A and B, to a common shape if they are compatible for broadcasting,\n",
        "    according to the PyTorch broadcasting rules. This function first checks if the tensors can be\n",
        "    broadcast together using the broad_together function. If they can, it uses the new_expand_as\n",
        "    function to broadcast each tensor to the common shape.\n",
        "\n",
        "    Args:\n",
        "        A (Tensor): The first tensor to be broadcast.\n",
        "        B (Tensor): The second tensor to be broadcast.\n",
        "\n",
        "    Returns:\n",
        "        (Tensor, Tensor): A tuple containing two tensors broadcast to the common shape.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If tensors A and B cannot be broadcast together according to broadcasting rules.\n",
        "\n",
        "    Example:\n",
        "        >>> A = torch.tensor([1, 2, 3])\n",
        "        >>> B = torch.tensor([[0], [1], [2]])\n",
        "        >>> C, D = new_broadcast_tensors(A, B)\n",
        "        >>> print(C)\n",
        "        >>> print(D)\n",
        "        tensor([[1, 2, 3],\n",
        "                [1, 2, 3],\n",
        "                [1, 2, 3]])\n",
        "        tensor([[0, 0, 0],\n",
        "                [1, 1, 1],\n",
        "                [2, 2, 2]])\n",
        "    \"\"\"\n",
        "    can_broadcast, broadcast_shape = broad_together(A, B)\n",
        "    if not can_broadcast:\n",
        "          raise RuntimeError(f\"expand_as: The size of shape A: ({A.shape}) must match the shape of tensor B ({ B.shape}) at non-singleton dimension.\")\n",
        "\n",
        "    # Broadcasting A and B to the common shape.\n",
        "    C = new_expand_as(A, torch.empty(broadcast_shape))\n",
        "    D = new_expand_as(B, torch.empty(broadcast_shape))\n",
        "\n",
        "    return C, D\n",
        "\n",
        "# Usage example\n",
        "x = torch.arange(3).reshape(1,3)\n",
        "y = torch.arange(2).reshape(2,1)\n",
        "print(x, y, sep='\\n\\n')\n",
        "print('\\n')\n",
        "a,b = torch.broadcast_tensors(x, y)\n",
        "print(a, b, sep='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcwH-GR31Yh3",
        "outputId": "f08e23aa-9da4-4546-9793-3a36f4eed6cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2]])\n",
            "\n",
            "tensor([[0],\n",
            "        [1]])\n",
            "\n",
            "\n",
            "tensor([[0, 1, 2],\n",
            "        [0, 1, 2]])\n",
            "\n",
            "tensor([[0, 0, 0],\n",
            "        [1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### סעיף ד"
      ],
      "metadata": {
        "id": "Drq1G4461eH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "expand_as function"
      ],
      "metadata": {
        "id": "ox7u1-5S1fub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, 2, 1)\n",
        "y = torch.rand(2,1)\n",
        "\n",
        "print(f'Built-in PyTorch expand_as: {y.expand_as(x)}')\n",
        "print('\\n')\n",
        "print(f'Custom Function new_expand_as: {new_expand_as(y,x)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTW7QLCH1hke",
        "outputId": "164c4810-50ee-4b84-aa3a-0c2e44d81178"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: tensor([[[0.0605],\n",
            "         [0.1956]],\n",
            "\n",
            "        [[0.0605],\n",
            "         [0.1956]],\n",
            "\n",
            "        [[0.0605],\n",
            "         [0.1956]]])\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: tensor([[[0.0605],\n",
            "         [0.1956]],\n",
            "\n",
            "        [[0.0605],\n",
            "         [0.1956]],\n",
            "\n",
            "        [[0.0605],\n",
            "         [0.1956]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1, 1)\n",
        "y = torch.rand(2,1)\n",
        "\n",
        "try:\n",
        "    result = y.expand_as(x)\n",
        "    print(f'Built-in PyTorch expand_as result: {result}')\n",
        "except RuntimeError as e:\n",
        "    print(f'Built-in PyTorch expand_as: RuntimeError - {e}')\n",
        "\n",
        "print('\\n')  # Newline for readability\n",
        "\n",
        "# Attempt to use your custom new_expand_as function\n",
        "try:\n",
        "    result = new_expand_as(y, x)\n",
        "    print(f'Custom Function new_expand_as result: {result}')\n",
        "except RuntimeError as e:\n",
        "    print(f'Custom Function new_expand_as: RuntimeError - {e}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03O4oDEl1imB",
        "outputId": "2d9448bc-cb8c-4e8a-c7c9-15177a51378e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: RuntimeError - The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1, 1].  Tensor sizes: [2, 1]\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: RuntimeError - expand_as: The size of the source tensor (torch.Size([2, 1])) must match the size of the target tensor (torch.Size([1, 1])) at non-singleton dimension.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, 2, 1,5,6)\n",
        "y = torch.rand(5,6)\n",
        "\n",
        "print(f'Built-in PyTorch expand_as: {y.expand_as(x)}')\n",
        "print('\\n')\n",
        "print(f'Custom Function new_expand_as: {new_expand_as(y,x)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8W4Wgta1kPr",
        "outputId": "74b86e4b-e409-46b0-85ea-fb3c4b9f0bd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: tensor([[[[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]],\n",
            "\n",
            "\n",
            "         [[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]],\n",
            "\n",
            "\n",
            "         [[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]],\n",
            "\n",
            "\n",
            "         [[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]]]])\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: tensor([[[[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]],\n",
            "\n",
            "\n",
            "         [[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]],\n",
            "\n",
            "\n",
            "         [[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]],\n",
            "\n",
            "\n",
            "         [[[0.3339, 0.3446, 0.5054, 0.7979, 0.4828, 0.2407],\n",
            "           [0.0280, 0.3453, 0.8613, 0.2380, 0.1369, 0.0485],\n",
            "           [0.7146, 0.2735, 0.3231, 0.5393, 0.8435, 0.5303],\n",
            "           [0.4798, 0.6109, 0.9414, 0.5679, 0.2877, 0.4652],\n",
            "           [0.5059, 0.9895, 0.9409, 0.3458, 0.6983, 0.1570]]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(1,1,1,1)\n",
        "\n",
        "try:\n",
        "    result = y.expand_as(x)\n",
        "    print(f'Built-in PyTorch expand_as result: {result}')\n",
        "except RuntimeError as e:\n",
        "    print(f'Built-in PyTorch expand_as: RuntimeError - {e}')\n",
        "\n",
        "print('\\n')  # Newline for readability\n",
        "\n",
        "# Attempt to use your custom new_expand_as function\n",
        "try:\n",
        "    result = new_expand_as(y, x)\n",
        "    print(f'Custom Function new_expand_as result: {result}')\n",
        "except RuntimeError as e:\n",
        "    print(f'Custom Function new_expand_as: RuntimeError - {e}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pkk_ud21liR",
        "outputId": "52bdea88-6659-48d8-fc4b-fb96491d281c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: RuntimeError - expand(torch.FloatTensor{[1, 1, 1, 1]}, size=[2, 2]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (4)\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: RuntimeError - expand_as: The source tensor cannot have more dimensions than the target tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2,5,6,1,1)\n",
        "y = torch.rand(5,6,1,1)\n",
        "\n",
        "print(f'Built-in PyTorch expand_as: {y.expand_as(x)}')\n",
        "print('\\n')\n",
        "print(f'Custom Function new_expand_as: {new_expand_as(y,x)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS8B9yqn1mit",
        "outputId": "8a95655f-62b6-49ce-d9f7-75c1d7313289"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: tensor([[[[[[0.6685]],\n",
            "\n",
            "           [[0.4454]],\n",
            "\n",
            "           [[0.1453]],\n",
            "\n",
            "           [[0.6560]],\n",
            "\n",
            "           [[0.4037]],\n",
            "\n",
            "           [[0.9545]]],\n",
            "\n",
            "\n",
            "          [[[0.9027]],\n",
            "\n",
            "           [[0.5350]],\n",
            "\n",
            "           [[0.7284]],\n",
            "\n",
            "           [[0.3735]],\n",
            "\n",
            "           [[0.8037]],\n",
            "\n",
            "           [[0.3534]]],\n",
            "\n",
            "\n",
            "          [[[0.5313]],\n",
            "\n",
            "           [[0.6079]],\n",
            "\n",
            "           [[0.4667]],\n",
            "\n",
            "           [[0.2500]],\n",
            "\n",
            "           [[0.5297]],\n",
            "\n",
            "           [[0.3543]]],\n",
            "\n",
            "\n",
            "          [[[0.2114]],\n",
            "\n",
            "           [[0.3548]],\n",
            "\n",
            "           [[0.9892]],\n",
            "\n",
            "           [[0.3860]],\n",
            "\n",
            "           [[0.8929]],\n",
            "\n",
            "           [[0.5092]]],\n",
            "\n",
            "\n",
            "          [[[0.1782]],\n",
            "\n",
            "           [[0.2417]],\n",
            "\n",
            "           [[0.4081]],\n",
            "\n",
            "           [[0.1372]],\n",
            "\n",
            "           [[0.9968]],\n",
            "\n",
            "           [[0.1361]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0.6685]],\n",
            "\n",
            "           [[0.4454]],\n",
            "\n",
            "           [[0.1453]],\n",
            "\n",
            "           [[0.6560]],\n",
            "\n",
            "           [[0.4037]],\n",
            "\n",
            "           [[0.9545]]],\n",
            "\n",
            "\n",
            "          [[[0.9027]],\n",
            "\n",
            "           [[0.5350]],\n",
            "\n",
            "           [[0.7284]],\n",
            "\n",
            "           [[0.3735]],\n",
            "\n",
            "           [[0.8037]],\n",
            "\n",
            "           [[0.3534]]],\n",
            "\n",
            "\n",
            "          [[[0.5313]],\n",
            "\n",
            "           [[0.6079]],\n",
            "\n",
            "           [[0.4667]],\n",
            "\n",
            "           [[0.2500]],\n",
            "\n",
            "           [[0.5297]],\n",
            "\n",
            "           [[0.3543]]],\n",
            "\n",
            "\n",
            "          [[[0.2114]],\n",
            "\n",
            "           [[0.3548]],\n",
            "\n",
            "           [[0.9892]],\n",
            "\n",
            "           [[0.3860]],\n",
            "\n",
            "           [[0.8929]],\n",
            "\n",
            "           [[0.5092]]],\n",
            "\n",
            "\n",
            "          [[[0.1782]],\n",
            "\n",
            "           [[0.2417]],\n",
            "\n",
            "           [[0.4081]],\n",
            "\n",
            "           [[0.1372]],\n",
            "\n",
            "           [[0.9968]],\n",
            "\n",
            "           [[0.1361]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[0.6685]],\n",
            "\n",
            "           [[0.4454]],\n",
            "\n",
            "           [[0.1453]],\n",
            "\n",
            "           [[0.6560]],\n",
            "\n",
            "           [[0.4037]],\n",
            "\n",
            "           [[0.9545]]],\n",
            "\n",
            "\n",
            "          [[[0.9027]],\n",
            "\n",
            "           [[0.5350]],\n",
            "\n",
            "           [[0.7284]],\n",
            "\n",
            "           [[0.3735]],\n",
            "\n",
            "           [[0.8037]],\n",
            "\n",
            "           [[0.3534]]],\n",
            "\n",
            "\n",
            "          [[[0.5313]],\n",
            "\n",
            "           [[0.6079]],\n",
            "\n",
            "           [[0.4667]],\n",
            "\n",
            "           [[0.2500]],\n",
            "\n",
            "           [[0.5297]],\n",
            "\n",
            "           [[0.3543]]],\n",
            "\n",
            "\n",
            "          [[[0.2114]],\n",
            "\n",
            "           [[0.3548]],\n",
            "\n",
            "           [[0.9892]],\n",
            "\n",
            "           [[0.3860]],\n",
            "\n",
            "           [[0.8929]],\n",
            "\n",
            "           [[0.5092]]],\n",
            "\n",
            "\n",
            "          [[[0.1782]],\n",
            "\n",
            "           [[0.2417]],\n",
            "\n",
            "           [[0.4081]],\n",
            "\n",
            "           [[0.1372]],\n",
            "\n",
            "           [[0.9968]],\n",
            "\n",
            "           [[0.1361]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0.6685]],\n",
            "\n",
            "           [[0.4454]],\n",
            "\n",
            "           [[0.1453]],\n",
            "\n",
            "           [[0.6560]],\n",
            "\n",
            "           [[0.4037]],\n",
            "\n",
            "           [[0.9545]]],\n",
            "\n",
            "\n",
            "          [[[0.9027]],\n",
            "\n",
            "           [[0.5350]],\n",
            "\n",
            "           [[0.7284]],\n",
            "\n",
            "           [[0.3735]],\n",
            "\n",
            "           [[0.8037]],\n",
            "\n",
            "           [[0.3534]]],\n",
            "\n",
            "\n",
            "          [[[0.5313]],\n",
            "\n",
            "           [[0.6079]],\n",
            "\n",
            "           [[0.4667]],\n",
            "\n",
            "           [[0.2500]],\n",
            "\n",
            "           [[0.5297]],\n",
            "\n",
            "           [[0.3543]]],\n",
            "\n",
            "\n",
            "          [[[0.2114]],\n",
            "\n",
            "           [[0.3548]],\n",
            "\n",
            "           [[0.9892]],\n",
            "\n",
            "           [[0.3860]],\n",
            "\n",
            "           [[0.8929]],\n",
            "\n",
            "           [[0.5092]]],\n",
            "\n",
            "\n",
            "          [[[0.1782]],\n",
            "\n",
            "           [[0.2417]],\n",
            "\n",
            "           [[0.4081]],\n",
            "\n",
            "           [[0.1372]],\n",
            "\n",
            "           [[0.9968]],\n",
            "\n",
            "           [[0.1361]]]]]])\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: tensor([[[[[[0.6685]],\n",
            "\n",
            "           [[0.4454]],\n",
            "\n",
            "           [[0.1453]],\n",
            "\n",
            "           [[0.6560]],\n",
            "\n",
            "           [[0.4037]],\n",
            "\n",
            "           [[0.9545]]],\n",
            "\n",
            "\n",
            "          [[[0.9027]],\n",
            "\n",
            "           [[0.5350]],\n",
            "\n",
            "           [[0.7284]],\n",
            "\n",
            "           [[0.3735]],\n",
            "\n",
            "           [[0.8037]],\n",
            "\n",
            "           [[0.3534]]],\n",
            "\n",
            "\n",
            "          [[[0.5313]],\n",
            "\n",
            "           [[0.6079]],\n",
            "\n",
            "           [[0.4667]],\n",
            "\n",
            "           [[0.2500]],\n",
            "\n",
            "           [[0.5297]],\n",
            "\n",
            "           [[0.3543]]],\n",
            "\n",
            "\n",
            "          [[[0.2114]],\n",
            "\n",
            "           [[0.3548]],\n",
            "\n",
            "           [[0.9892]],\n",
            "\n",
            "           [[0.3860]],\n",
            "\n",
            "           [[0.8929]],\n",
            "\n",
            "           [[0.5092]]],\n",
            "\n",
            "\n",
            "          [[[0.1782]],\n",
            "\n",
            "           [[0.2417]],\n",
            "\n",
            "           [[0.4081]],\n",
            "\n",
            "           [[0.1372]],\n",
            "\n",
            "           [[0.9968]],\n",
            "\n",
            "           [[0.1361]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0.6685]],\n",
            "\n",
            "           [[0.4454]],\n",
            "\n",
            "           [[0.1453]],\n",
            "\n",
            "           [[0.6560]],\n",
            "\n",
            "           [[0.4037]],\n",
            "\n",
            "           [[0.9545]]],\n",
            "\n",
            "\n",
            "          [[[0.9027]],\n",
            "\n",
            "           [[0.5350]],\n",
            "\n",
            "           [[0.7284]],\n",
            "\n",
            "           [[0.3735]],\n",
            "\n",
            "           [[0.8037]],\n",
            "\n",
            "           [[0.3534]]],\n",
            "\n",
            "\n",
            "          [[[0.5313]],\n",
            "\n",
            "           [[0.6079]],\n",
            "\n",
            "           [[0.4667]],\n",
            "\n",
            "           [[0.2500]],\n",
            "\n",
            "           [[0.5297]],\n",
            "\n",
            "           [[0.3543]]],\n",
            "\n",
            "\n",
            "          [[[0.2114]],\n",
            "\n",
            "           [[0.3548]],\n",
            "\n",
            "           [[0.9892]],\n",
            "\n",
            "           [[0.3860]],\n",
            "\n",
            "           [[0.8929]],\n",
            "\n",
            "           [[0.5092]]],\n",
            "\n",
            "\n",
            "          [[[0.1782]],\n",
            "\n",
            "           [[0.2417]],\n",
            "\n",
            "           [[0.4081]],\n",
            "\n",
            "           [[0.1372]],\n",
            "\n",
            "           [[0.9968]],\n",
            "\n",
            "           [[0.1361]]]]],\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        [[[[[0.6685]],\n",
            "\n",
            "           [[0.4454]],\n",
            "\n",
            "           [[0.1453]],\n",
            "\n",
            "           [[0.6560]],\n",
            "\n",
            "           [[0.4037]],\n",
            "\n",
            "           [[0.9545]]],\n",
            "\n",
            "\n",
            "          [[[0.9027]],\n",
            "\n",
            "           [[0.5350]],\n",
            "\n",
            "           [[0.7284]],\n",
            "\n",
            "           [[0.3735]],\n",
            "\n",
            "           [[0.8037]],\n",
            "\n",
            "           [[0.3534]]],\n",
            "\n",
            "\n",
            "          [[[0.5313]],\n",
            "\n",
            "           [[0.6079]],\n",
            "\n",
            "           [[0.4667]],\n",
            "\n",
            "           [[0.2500]],\n",
            "\n",
            "           [[0.5297]],\n",
            "\n",
            "           [[0.3543]]],\n",
            "\n",
            "\n",
            "          [[[0.2114]],\n",
            "\n",
            "           [[0.3548]],\n",
            "\n",
            "           [[0.9892]],\n",
            "\n",
            "           [[0.3860]],\n",
            "\n",
            "           [[0.8929]],\n",
            "\n",
            "           [[0.5092]]],\n",
            "\n",
            "\n",
            "          [[[0.1782]],\n",
            "\n",
            "           [[0.2417]],\n",
            "\n",
            "           [[0.4081]],\n",
            "\n",
            "           [[0.1372]],\n",
            "\n",
            "           [[0.9968]],\n",
            "\n",
            "           [[0.1361]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0.6685]],\n",
            "\n",
            "           [[0.4454]],\n",
            "\n",
            "           [[0.1453]],\n",
            "\n",
            "           [[0.6560]],\n",
            "\n",
            "           [[0.4037]],\n",
            "\n",
            "           [[0.9545]]],\n",
            "\n",
            "\n",
            "          [[[0.9027]],\n",
            "\n",
            "           [[0.5350]],\n",
            "\n",
            "           [[0.7284]],\n",
            "\n",
            "           [[0.3735]],\n",
            "\n",
            "           [[0.8037]],\n",
            "\n",
            "           [[0.3534]]],\n",
            "\n",
            "\n",
            "          [[[0.5313]],\n",
            "\n",
            "           [[0.6079]],\n",
            "\n",
            "           [[0.4667]],\n",
            "\n",
            "           [[0.2500]],\n",
            "\n",
            "           [[0.5297]],\n",
            "\n",
            "           [[0.3543]]],\n",
            "\n",
            "\n",
            "          [[[0.2114]],\n",
            "\n",
            "           [[0.3548]],\n",
            "\n",
            "           [[0.9892]],\n",
            "\n",
            "           [[0.3860]],\n",
            "\n",
            "           [[0.8929]],\n",
            "\n",
            "           [[0.5092]]],\n",
            "\n",
            "\n",
            "          [[[0.1782]],\n",
            "\n",
            "           [[0.2417]],\n",
            "\n",
            "           [[0.4081]],\n",
            "\n",
            "           [[0.1372]],\n",
            "\n",
            "           [[0.9968]],\n",
            "\n",
            "           [[0.1361]]]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.broadcast_tensors"
      ],
      "metadata": {
        "id": "tHhHsiUH1oPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, 2, 1)\n",
        "y = torch.rand(2,1)\n",
        "\n",
        "print(f'Built-in PyTorch expand_as: {torch.broadcast_tensors(x,y)}')\n",
        "print('\\n')\n",
        "print(f'Custom Function new_expand_as: {new_broadcast_tensors(x,y)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72CcxUw81rP0",
        "outputId": "7050c4e1-2fb0-4745-8e40-8d3462302a66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: (tensor([[[0.0450],\n",
            "         [0.1396]],\n",
            "\n",
            "        [[0.4657],\n",
            "         [0.0481]],\n",
            "\n",
            "        [[0.3457],\n",
            "         [0.6171]]]), tensor([[[0.6849],\n",
            "         [0.0965]],\n",
            "\n",
            "        [[0.6849],\n",
            "         [0.0965]],\n",
            "\n",
            "        [[0.6849],\n",
            "         [0.0965]]]))\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: (tensor([[[0.0450],\n",
            "         [0.1396]],\n",
            "\n",
            "        [[0.4657],\n",
            "         [0.0481]],\n",
            "\n",
            "        [[0.3457],\n",
            "         [0.6171]]]), tensor([[[0.6849],\n",
            "         [0.0965]],\n",
            "\n",
            "        [[0.6849],\n",
            "         [0.0965]],\n",
            "\n",
            "        [[0.6849],\n",
            "         [0.0965]]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3, 1, 2)\n",
        "y = torch.rand(2)\n",
        "\n",
        "print(f'Built-in PyTorch expand_as: {torch.broadcast_tensors(x,y)}')\n",
        "print('\\n')\n",
        "print(f'Custom Function new_expand_as: {new_broadcast_tensors(x,y)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVcwMn4r1sjG",
        "outputId": "96d9fa3e-43f1-4a4b-c482-c3e75789a6ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: (tensor([[[0.8606, 0.4244]],\n",
            "\n",
            "        [[0.3882, 0.1140]],\n",
            "\n",
            "        [[0.2720, 0.7793]]]), tensor([[[0.3793, 0.6160]],\n",
            "\n",
            "        [[0.3793, 0.6160]],\n",
            "\n",
            "        [[0.3793, 0.6160]]]))\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: (tensor([[[0.8606, 0.4244]],\n",
            "\n",
            "        [[0.3882, 0.1140]],\n",
            "\n",
            "        [[0.2720, 0.7793]]]), tensor([[[0.3793, 0.6160]],\n",
            "\n",
            "        [[0.3793, 0.6160]],\n",
            "\n",
            "        [[0.3793, 0.6160]]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3,1,1)\n",
        "y = torch.rand(1,2,3)\n",
        "\n",
        "print(f'Built-in PyTorch expand_as: {torch.broadcast_tensors(x,y)}')\n",
        "print('\\n')\n",
        "print(f'Custom Function new_expand_as: {new_broadcast_tensors(x,y)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEVTXb5m1uDp",
        "outputId": "01aaf660-78f3-4a97-f2b9-30ffbc581f00"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: (tensor([[[0.2342, 0.2342, 0.2342],\n",
            "         [0.2342, 0.2342, 0.2342]],\n",
            "\n",
            "        [[0.2804, 0.2804, 0.2804],\n",
            "         [0.2804, 0.2804, 0.2804]],\n",
            "\n",
            "        [[0.4202, 0.4202, 0.4202],\n",
            "         [0.4202, 0.4202, 0.4202]]]), tensor([[[0.2078, 0.2814, 0.5411],\n",
            "         [0.5726, 0.6154, 0.3828]],\n",
            "\n",
            "        [[0.2078, 0.2814, 0.5411],\n",
            "         [0.5726, 0.6154, 0.3828]],\n",
            "\n",
            "        [[0.2078, 0.2814, 0.5411],\n",
            "         [0.5726, 0.6154, 0.3828]]]))\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: (tensor([[[0.2342, 0.2342, 0.2342],\n",
            "         [0.2342, 0.2342, 0.2342]],\n",
            "\n",
            "        [[0.2804, 0.2804, 0.2804],\n",
            "         [0.2804, 0.2804, 0.2804]],\n",
            "\n",
            "        [[0.4202, 0.4202, 0.4202],\n",
            "         [0.4202, 0.4202, 0.4202]]]), tensor([[[0.2078, 0.2814, 0.5411],\n",
            "         [0.5726, 0.6154, 0.3828]],\n",
            "\n",
            "        [[0.2078, 0.2814, 0.5411],\n",
            "         [0.5726, 0.6154, 0.3828]],\n",
            "\n",
            "        [[0.2078, 0.2814, 0.5411],\n",
            "         [0.5726, 0.6154, 0.3828]]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1,2,1)\n",
        "y = torch.rand(2,1)\n",
        "\n",
        "print(f'Built-in PyTorch expand_as: {torch.broadcast_tensors(x,y)}')\n",
        "print('\\n')\n",
        "print(f'Custom Function new_expand_as: {new_broadcast_tensors(x,y)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFwO6nd81u_x",
        "outputId": "9c1ae040-1ee4-4f7b-b2f6-bf563afb1174"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: (tensor([[[0.9171],\n",
            "         [0.1911]]]), tensor([[[0.6841],\n",
            "         [0.1534]]]))\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: (tensor([[[0.9171],\n",
            "         [0.1911]]]), tensor([[[0.6841],\n",
            "         [0.1534]]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1,3,2,4)\n",
        "y = torch.rand(1,2,3,4)\n",
        "\n",
        "try:\n",
        "    result = torch.broadcast_tensors(x,y)\n",
        "    print(f'Built-in PyTorch expand_as result: {result}')\n",
        "except RuntimeError as e:\n",
        "    print(f'Built-in PyTorch expand_as: RuntimeError - {e}')\n",
        "\n",
        "print('\\n')  # Newline for readability\n",
        "\n",
        "# Attempt to use your custom new_expand_as function\n",
        "try:\n",
        "    result = new_broadcast_tensors(x,y)\n",
        "    print(f'Custom Function new_expand_as result: {result}')\n",
        "except RuntimeError as e:\n",
        "    print(f'Custom Function new_expand_as: RuntimeError - {e}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxIsekQV1v--",
        "outputId": "45d51f02-85ed-417b-c5cf-a77aae1d30da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as: RuntimeError - The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 2\n",
            "\n",
            "\n",
            "Custom Function new_expand_as: RuntimeError - expand_as: The size of shape A: (torch.Size([1, 3, 2, 4])) must match the shape of tensor B (torch.Size([1, 2, 3, 4])) at non-singleton dimension.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1,3,2,4,4,4)\n",
        "y = torch.rand(1,3,2,1,4,1)\n",
        "\n",
        "try:\n",
        "    result = torch.broadcast_tensors(x,y)\n",
        "    print(f'Built-in PyTorch expand_as result: {result}')\n",
        "except RuntimeError as e:\n",
        "    print(f'Built-in PyTorch expand_as: RuntimeError - {e}')\n",
        "\n",
        "print('\\n')  # Newline for readability\n",
        "\n",
        "# Attempt to use your custom new_expand_as function\n",
        "try:\n",
        "    result = new_broadcast_tensors(x,y)\n",
        "    print(f'Custom Function new_expand_as result: {result}')\n",
        "except RuntimeError as e:\n",
        "    print(f'Custom Function new_expand_as: RuntimeError - {e}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXmztTjd1w4W",
        "outputId": "80de2947-61c7-4a5c-8ff3-26629eace077"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built-in PyTorch expand_as result: (tensor([[[[[[5.9489e-01, 3.7390e-01, 6.5592e-01, 1.6016e-01],\n",
            "            [8.5774e-01, 2.3958e-01, 3.8752e-01, 5.2189e-01],\n",
            "            [8.4359e-02, 3.3185e-01, 9.7628e-01, 9.6863e-01],\n",
            "            [1.9198e-01, 7.9117e-02, 4.5457e-01, 3.1727e-01]],\n",
            "\n",
            "           [[1.4621e-01, 2.1859e-01, 6.7634e-02, 5.6933e-01],\n",
            "            [1.5976e-01, 2.2818e-01, 4.3407e-01, 2.5148e-01],\n",
            "            [2.1769e-01, 4.7259e-01, 4.7289e-01, 3.6035e-01],\n",
            "            [3.1312e-01, 8.3445e-01, 8.2336e-01, 5.4761e-01]],\n",
            "\n",
            "           [[2.4839e-01, 7.4842e-01, 9.0397e-01, 3.6518e-01],\n",
            "            [7.8055e-01, 1.5179e-01, 3.1445e-02, 5.4399e-01],\n",
            "            [3.2665e-01, 9.3265e-01, 5.8034e-01, 4.5060e-01],\n",
            "            [5.6894e-01, 2.6298e-02, 7.8849e-01, 9.6303e-01]],\n",
            "\n",
            "           [[6.2809e-01, 1.6547e-01, 4.8911e-01, 2.7286e-01],\n",
            "            [9.0458e-01, 7.3731e-01, 7.3335e-01, 8.7035e-01],\n",
            "            [6.5777e-01, 5.6197e-01, 7.4077e-01, 9.2477e-01],\n",
            "            [7.1126e-01, 3.9247e-01, 2.4241e-01, 4.9758e-01]]],\n",
            "\n",
            "\n",
            "          [[[9.8704e-01, 1.4244e-02, 4.5241e-01, 3.8164e-01],\n",
            "            [1.7987e-01, 5.5428e-01, 7.1007e-01, 2.4841e-02],\n",
            "            [6.0780e-01, 1.0293e-01, 2.0700e-01, 3.6293e-01],\n",
            "            [5.9659e-01, 1.4801e-01, 4.4311e-01, 9.9989e-01]],\n",
            "\n",
            "           [[2.5654e-01, 8.2434e-01, 6.4923e-01, 6.3646e-01],\n",
            "            [8.8934e-01, 3.4706e-02, 4.2039e-01, 9.2810e-01],\n",
            "            [4.1078e-01, 7.9751e-01, 3.1117e-01, 8.8708e-01],\n",
            "            [9.6998e-01, 4.6295e-01, 9.1161e-01, 9.4232e-01]],\n",
            "\n",
            "           [[4.3481e-01, 1.3828e-01, 2.3863e-01, 3.7004e-01],\n",
            "            [1.0574e-01, 8.0883e-01, 9.6762e-01, 5.3288e-01],\n",
            "            [3.4199e-01, 6.1658e-01, 3.3340e-01, 6.9044e-01],\n",
            "            [7.1095e-01, 5.1136e-01, 5.6107e-01, 5.2494e-02]],\n",
            "\n",
            "           [[6.8536e-02, 7.1854e-01, 5.1557e-01, 5.4132e-01],\n",
            "            [6.1737e-01, 5.4781e-01, 7.5682e-01, 7.8203e-01],\n",
            "            [4.8511e-01, 2.1522e-01, 8.0915e-01, 6.9725e-01],\n",
            "            [8.3667e-01, 3.7234e-01, 9.7717e-01, 3.5038e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[4.5341e-01, 9.4840e-01, 9.0525e-01, 7.9226e-01],\n",
            "            [9.6837e-01, 6.8175e-01, 1.7241e-01, 6.0848e-02],\n",
            "            [2.4931e-01, 1.7608e-01, 9.1658e-01, 3.1465e-01],\n",
            "            [7.0870e-01, 9.9517e-01, 7.5808e-01, 9.6635e-01]],\n",
            "\n",
            "           [[2.7631e-01, 4.5871e-01, 6.2294e-01, 5.2689e-02],\n",
            "            [2.4608e-01, 6.7778e-01, 1.0592e-01, 1.5947e-01],\n",
            "            [1.5484e-02, 4.2279e-01, 8.2825e-01, 2.7133e-01],\n",
            "            [5.7999e-01, 4.3421e-01, 2.0192e-01, 7.6669e-01]],\n",
            "\n",
            "           [[1.7834e-01, 8.2791e-01, 1.4190e-01, 1.5137e-01],\n",
            "            [3.8952e-01, 3.9133e-01, 6.0046e-02, 9.4618e-01],\n",
            "            [7.9038e-01, 8.2921e-02, 8.8869e-01, 6.6696e-03],\n",
            "            [4.3635e-01, 7.9577e-01, 3.4810e-01, 9.5145e-01]],\n",
            "\n",
            "           [[2.4902e-01, 8.0098e-02, 6.0694e-01, 6.9724e-01],\n",
            "            [5.1892e-01, 4.0681e-01, 5.1597e-01, 8.8042e-01],\n",
            "            [2.8744e-01, 8.4325e-01, 3.8192e-01, 1.9388e-01],\n",
            "            [7.0656e-02, 6.6799e-01, 6.4408e-01, 7.0485e-01]]],\n",
            "\n",
            "\n",
            "          [[[5.8015e-01, 7.6424e-01, 2.5119e-01, 8.8418e-01],\n",
            "            [1.7943e-01, 2.8721e-01, 6.4228e-02, 7.6908e-01],\n",
            "            [2.0805e-01, 9.5915e-01, 9.3598e-01, 9.5323e-01],\n",
            "            [3.7928e-01, 4.9253e-01, 4.8387e-01, 5.4833e-01]],\n",
            "\n",
            "           [[5.9213e-01, 7.2086e-01, 4.5739e-01, 4.5792e-01],\n",
            "            [2.2265e-01, 5.2966e-01, 4.6030e-01, 9.5269e-01],\n",
            "            [4.3458e-01, 1.4386e-01, 1.5352e-01, 8.3753e-01],\n",
            "            [7.1899e-01, 3.3962e-01, 3.1829e-05, 6.9245e-01]],\n",
            "\n",
            "           [[3.9963e-01, 5.3041e-01, 3.0805e-01, 5.9012e-01],\n",
            "            [7.0054e-01, 5.5700e-01, 1.3914e-01, 4.2234e-01],\n",
            "            [2.5089e-01, 2.4460e-01, 4.5050e-01, 8.6132e-01],\n",
            "            [7.2481e-01, 6.1727e-03, 7.5898e-02, 3.4437e-01]],\n",
            "\n",
            "           [[2.2053e-01, 3.1767e-01, 5.0666e-01, 3.1909e-01],\n",
            "            [1.5084e-01, 4.0104e-01, 6.4741e-01, 6.8497e-01],\n",
            "            [6.2270e-01, 6.8573e-03, 3.3469e-01, 9.1387e-01],\n",
            "            [1.3210e-01, 7.3397e-01, 1.9899e-01, 4.6350e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[8.3083e-02, 3.0082e-01, 7.7207e-01, 7.3871e-01],\n",
            "            [3.3457e-01, 2.8575e-01, 2.7343e-01, 8.3768e-01],\n",
            "            [9.8232e-01, 3.7361e-01, 5.9171e-01, 1.6792e-01],\n",
            "            [3.3130e-01, 4.6843e-01, 3.4851e-01, 7.4090e-01]],\n",
            "\n",
            "           [[4.3311e-01, 7.6890e-01, 5.8960e-01, 8.1048e-01],\n",
            "            [1.0736e-01, 2.4125e-03, 5.0246e-01, 5.9908e-01],\n",
            "            [7.8102e-01, 9.3186e-01, 7.2754e-01, 6.2892e-01],\n",
            "            [6.6651e-01, 4.7026e-01, 3.2028e-01, 6.8491e-01]],\n",
            "\n",
            "           [[6.6458e-01, 5.1829e-01, 3.5684e-01, 4.8835e-01],\n",
            "            [9.4437e-01, 4.3659e-01, 7.3710e-01, 1.0054e-01],\n",
            "            [3.3276e-02, 7.1691e-01, 9.5096e-01, 2.1225e-02],\n",
            "            [7.7069e-01, 9.1081e-01, 5.2285e-01, 7.4272e-01]],\n",
            "\n",
            "           [[5.0578e-03, 4.4227e-01, 8.0025e-01, 5.6609e-01],\n",
            "            [7.8755e-01, 1.2177e-01, 2.0332e-01, 8.2272e-01],\n",
            "            [4.4426e-01, 3.9598e-01, 9.7693e-01, 2.4276e-01],\n",
            "            [5.2707e-01, 1.2436e-01, 1.9854e-02, 1.8292e-01]]],\n",
            "\n",
            "\n",
            "          [[[8.9961e-01, 4.7383e-01, 8.5570e-02, 9.1276e-01],\n",
            "            [8.9534e-01, 4.3118e-02, 7.8137e-01, 8.0820e-01],\n",
            "            [9.6610e-01, 6.9946e-01, 4.3547e-01, 3.0553e-01],\n",
            "            [2.7306e-01, 8.1155e-01, 8.2116e-02, 9.2640e-01]],\n",
            "\n",
            "           [[1.4615e-01, 8.7510e-02, 6.3726e-02, 4.4800e-01],\n",
            "            [4.4567e-01, 4.0293e-01, 3.0219e-01, 3.5363e-01],\n",
            "            [5.9592e-02, 2.6398e-01, 9.0231e-01, 4.2637e-01],\n",
            "            [8.3676e-01, 5.5954e-01, 3.5128e-01, 8.1588e-01]],\n",
            "\n",
            "           [[2.6093e-01, 3.5660e-01, 4.5906e-03, 6.0552e-01],\n",
            "            [1.9749e-01, 9.1857e-01, 1.1674e-01, 9.5905e-01],\n",
            "            [2.2287e-01, 5.5386e-01, 9.4023e-01, 7.0456e-01],\n",
            "            [9.7401e-01, 4.0393e-01, 6.7069e-01, 7.0269e-01]],\n",
            "\n",
            "           [[3.1589e-01, 9.7855e-01, 4.0681e-02, 5.2715e-01],\n",
            "            [9.1474e-01, 6.9765e-01, 2.5878e-01, 5.1174e-01],\n",
            "            [7.3690e-01, 9.3278e-01, 3.3872e-01, 4.8221e-01],\n",
            "            [4.0273e-01, 9.4622e-01, 4.8297e-01, 6.1675e-02]]]]]]), tensor([[[[[[0.6380, 0.6380, 0.6380, 0.6380],\n",
            "            [0.4935, 0.4935, 0.4935, 0.4935],\n",
            "            [0.3643, 0.3643, 0.3643, 0.3643],\n",
            "            [0.9226, 0.9226, 0.9226, 0.9226]],\n",
            "\n",
            "           [[0.6380, 0.6380, 0.6380, 0.6380],\n",
            "            [0.4935, 0.4935, 0.4935, 0.4935],\n",
            "            [0.3643, 0.3643, 0.3643, 0.3643],\n",
            "            [0.9226, 0.9226, 0.9226, 0.9226]],\n",
            "\n",
            "           [[0.6380, 0.6380, 0.6380, 0.6380],\n",
            "            [0.4935, 0.4935, 0.4935, 0.4935],\n",
            "            [0.3643, 0.3643, 0.3643, 0.3643],\n",
            "            [0.9226, 0.9226, 0.9226, 0.9226]],\n",
            "\n",
            "           [[0.6380, 0.6380, 0.6380, 0.6380],\n",
            "            [0.4935, 0.4935, 0.4935, 0.4935],\n",
            "            [0.3643, 0.3643, 0.3643, 0.3643],\n",
            "            [0.9226, 0.9226, 0.9226, 0.9226]]],\n",
            "\n",
            "\n",
            "          [[[0.1880, 0.1880, 0.1880, 0.1880],\n",
            "            [0.4415, 0.4415, 0.4415, 0.4415],\n",
            "            [0.3922, 0.3922, 0.3922, 0.3922],\n",
            "            [0.8518, 0.8518, 0.8518, 0.8518]],\n",
            "\n",
            "           [[0.1880, 0.1880, 0.1880, 0.1880],\n",
            "            [0.4415, 0.4415, 0.4415, 0.4415],\n",
            "            [0.3922, 0.3922, 0.3922, 0.3922],\n",
            "            [0.8518, 0.8518, 0.8518, 0.8518]],\n",
            "\n",
            "           [[0.1880, 0.1880, 0.1880, 0.1880],\n",
            "            [0.4415, 0.4415, 0.4415, 0.4415],\n",
            "            [0.3922, 0.3922, 0.3922, 0.3922],\n",
            "            [0.8518, 0.8518, 0.8518, 0.8518]],\n",
            "\n",
            "           [[0.1880, 0.1880, 0.1880, 0.1880],\n",
            "            [0.4415, 0.4415, 0.4415, 0.4415],\n",
            "            [0.3922, 0.3922, 0.3922, 0.3922],\n",
            "            [0.8518, 0.8518, 0.8518, 0.8518]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0.9025, 0.9025, 0.9025, 0.9025],\n",
            "            [0.1892, 0.1892, 0.1892, 0.1892],\n",
            "            [0.7895, 0.7895, 0.7895, 0.7895],\n",
            "            [0.9392, 0.9392, 0.9392, 0.9392]],\n",
            "\n",
            "           [[0.9025, 0.9025, 0.9025, 0.9025],\n",
            "            [0.1892, 0.1892, 0.1892, 0.1892],\n",
            "            [0.7895, 0.7895, 0.7895, 0.7895],\n",
            "            [0.9392, 0.9392, 0.9392, 0.9392]],\n",
            "\n",
            "           [[0.9025, 0.9025, 0.9025, 0.9025],\n",
            "            [0.1892, 0.1892, 0.1892, 0.1892],\n",
            "            [0.7895, 0.7895, 0.7895, 0.7895],\n",
            "            [0.9392, 0.9392, 0.9392, 0.9392]],\n",
            "\n",
            "           [[0.9025, 0.9025, 0.9025, 0.9025],\n",
            "            [0.1892, 0.1892, 0.1892, 0.1892],\n",
            "            [0.7895, 0.7895, 0.7895, 0.7895],\n",
            "            [0.9392, 0.9392, 0.9392, 0.9392]]],\n",
            "\n",
            "\n",
            "          [[[0.6707, 0.6707, 0.6707, 0.6707],\n",
            "            [0.0878, 0.0878, 0.0878, 0.0878],\n",
            "            [0.3023, 0.3023, 0.3023, 0.3023],\n",
            "            [0.0477, 0.0477, 0.0477, 0.0477]],\n",
            "\n",
            "           [[0.6707, 0.6707, 0.6707, 0.6707],\n",
            "            [0.0878, 0.0878, 0.0878, 0.0878],\n",
            "            [0.3023, 0.3023, 0.3023, 0.3023],\n",
            "            [0.0477, 0.0477, 0.0477, 0.0477]],\n",
            "\n",
            "           [[0.6707, 0.6707, 0.6707, 0.6707],\n",
            "            [0.0878, 0.0878, 0.0878, 0.0878],\n",
            "            [0.3023, 0.3023, 0.3023, 0.3023],\n",
            "            [0.0477, 0.0477, 0.0477, 0.0477]],\n",
            "\n",
            "           [[0.6707, 0.6707, 0.6707, 0.6707],\n",
            "            [0.0878, 0.0878, 0.0878, 0.0878],\n",
            "            [0.3023, 0.3023, 0.3023, 0.3023],\n",
            "            [0.0477, 0.0477, 0.0477, 0.0477]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0.0020, 0.0020, 0.0020, 0.0020],\n",
            "            [0.8567, 0.8567, 0.8567, 0.8567],\n",
            "            [0.3736, 0.3736, 0.3736, 0.3736],\n",
            "            [0.8432, 0.8432, 0.8432, 0.8432]],\n",
            "\n",
            "           [[0.0020, 0.0020, 0.0020, 0.0020],\n",
            "            [0.8567, 0.8567, 0.8567, 0.8567],\n",
            "            [0.3736, 0.3736, 0.3736, 0.3736],\n",
            "            [0.8432, 0.8432, 0.8432, 0.8432]],\n",
            "\n",
            "           [[0.0020, 0.0020, 0.0020, 0.0020],\n",
            "            [0.8567, 0.8567, 0.8567, 0.8567],\n",
            "            [0.3736, 0.3736, 0.3736, 0.3736],\n",
            "            [0.8432, 0.8432, 0.8432, 0.8432]],\n",
            "\n",
            "           [[0.0020, 0.0020, 0.0020, 0.0020],\n",
            "            [0.8567, 0.8567, 0.8567, 0.8567],\n",
            "            [0.3736, 0.3736, 0.3736, 0.3736],\n",
            "            [0.8432, 0.8432, 0.8432, 0.8432]]],\n",
            "\n",
            "\n",
            "          [[[0.8777, 0.8777, 0.8777, 0.8777],\n",
            "            [0.8050, 0.8050, 0.8050, 0.8050],\n",
            "            [0.9768, 0.9768, 0.9768, 0.9768],\n",
            "            [0.7433, 0.7433, 0.7433, 0.7433]],\n",
            "\n",
            "           [[0.8777, 0.8777, 0.8777, 0.8777],\n",
            "            [0.8050, 0.8050, 0.8050, 0.8050],\n",
            "            [0.9768, 0.9768, 0.9768, 0.9768],\n",
            "            [0.7433, 0.7433, 0.7433, 0.7433]],\n",
            "\n",
            "           [[0.8777, 0.8777, 0.8777, 0.8777],\n",
            "            [0.8050, 0.8050, 0.8050, 0.8050],\n",
            "            [0.9768, 0.9768, 0.9768, 0.9768],\n",
            "            [0.7433, 0.7433, 0.7433, 0.7433]],\n",
            "\n",
            "           [[0.8777, 0.8777, 0.8777, 0.8777],\n",
            "            [0.8050, 0.8050, 0.8050, 0.8050],\n",
            "            [0.9768, 0.9768, 0.9768, 0.9768],\n",
            "            [0.7433, 0.7433, 0.7433, 0.7433]]]]]]))\n",
            "\n",
            "\n",
            "Custom Function new_expand_as result: (tensor([[[[[[5.9489e-01, 3.7390e-01, 6.5592e-01, 1.6016e-01],\n",
            "            [8.5774e-01, 2.3958e-01, 3.8752e-01, 5.2189e-01],\n",
            "            [8.4359e-02, 3.3185e-01, 9.7628e-01, 9.6863e-01],\n",
            "            [1.9198e-01, 7.9117e-02, 4.5457e-01, 3.1727e-01]],\n",
            "\n",
            "           [[1.4621e-01, 2.1859e-01, 6.7634e-02, 5.6933e-01],\n",
            "            [1.5976e-01, 2.2818e-01, 4.3407e-01, 2.5148e-01],\n",
            "            [2.1769e-01, 4.7259e-01, 4.7289e-01, 3.6035e-01],\n",
            "            [3.1312e-01, 8.3445e-01, 8.2336e-01, 5.4761e-01]],\n",
            "\n",
            "           [[2.4839e-01, 7.4842e-01, 9.0397e-01, 3.6518e-01],\n",
            "            [7.8055e-01, 1.5179e-01, 3.1445e-02, 5.4399e-01],\n",
            "            [3.2665e-01, 9.3265e-01, 5.8034e-01, 4.5060e-01],\n",
            "            [5.6894e-01, 2.6298e-02, 7.8849e-01, 9.6303e-01]],\n",
            "\n",
            "           [[6.2809e-01, 1.6547e-01, 4.8911e-01, 2.7286e-01],\n",
            "            [9.0458e-01, 7.3731e-01, 7.3335e-01, 8.7035e-01],\n",
            "            [6.5777e-01, 5.6197e-01, 7.4077e-01, 9.2477e-01],\n",
            "            [7.1126e-01, 3.9247e-01, 2.4241e-01, 4.9758e-01]]],\n",
            "\n",
            "\n",
            "          [[[9.8704e-01, 1.4244e-02, 4.5241e-01, 3.8164e-01],\n",
            "            [1.7987e-01, 5.5428e-01, 7.1007e-01, 2.4841e-02],\n",
            "            [6.0780e-01, 1.0293e-01, 2.0700e-01, 3.6293e-01],\n",
            "            [5.9659e-01, 1.4801e-01, 4.4311e-01, 9.9989e-01]],\n",
            "\n",
            "           [[2.5654e-01, 8.2434e-01, 6.4923e-01, 6.3646e-01],\n",
            "            [8.8934e-01, 3.4706e-02, 4.2039e-01, 9.2810e-01],\n",
            "            [4.1078e-01, 7.9751e-01, 3.1117e-01, 8.8708e-01],\n",
            "            [9.6998e-01, 4.6295e-01, 9.1161e-01, 9.4232e-01]],\n",
            "\n",
            "           [[4.3481e-01, 1.3828e-01, 2.3863e-01, 3.7004e-01],\n",
            "            [1.0574e-01, 8.0883e-01, 9.6762e-01, 5.3288e-01],\n",
            "            [3.4199e-01, 6.1658e-01, 3.3340e-01, 6.9044e-01],\n",
            "            [7.1095e-01, 5.1136e-01, 5.6107e-01, 5.2494e-02]],\n",
            "\n",
            "           [[6.8536e-02, 7.1854e-01, 5.1557e-01, 5.4132e-01],\n",
            "            [6.1737e-01, 5.4781e-01, 7.5682e-01, 7.8203e-01],\n",
            "            [4.8511e-01, 2.1522e-01, 8.0915e-01, 6.9725e-01],\n",
            "            [8.3667e-01, 3.7234e-01, 9.7717e-01, 3.5038e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[4.5341e-01, 9.4840e-01, 9.0525e-01, 7.9226e-01],\n",
            "            [9.6837e-01, 6.8175e-01, 1.7241e-01, 6.0848e-02],\n",
            "            [2.4931e-01, 1.7608e-01, 9.1658e-01, 3.1465e-01],\n",
            "            [7.0870e-01, 9.9517e-01, 7.5808e-01, 9.6635e-01]],\n",
            "\n",
            "           [[2.7631e-01, 4.5871e-01, 6.2294e-01, 5.2689e-02],\n",
            "            [2.4608e-01, 6.7778e-01, 1.0592e-01, 1.5947e-01],\n",
            "            [1.5484e-02, 4.2279e-01, 8.2825e-01, 2.7133e-01],\n",
            "            [5.7999e-01, 4.3421e-01, 2.0192e-01, 7.6669e-01]],\n",
            "\n",
            "           [[1.7834e-01, 8.2791e-01, 1.4190e-01, 1.5137e-01],\n",
            "            [3.8952e-01, 3.9133e-01, 6.0046e-02, 9.4618e-01],\n",
            "            [7.9038e-01, 8.2921e-02, 8.8869e-01, 6.6696e-03],\n",
            "            [4.3635e-01, 7.9577e-01, 3.4810e-01, 9.5145e-01]],\n",
            "\n",
            "           [[2.4902e-01, 8.0098e-02, 6.0694e-01, 6.9724e-01],\n",
            "            [5.1892e-01, 4.0681e-01, 5.1597e-01, 8.8042e-01],\n",
            "            [2.8744e-01, 8.4325e-01, 3.8192e-01, 1.9388e-01],\n",
            "            [7.0656e-02, 6.6799e-01, 6.4408e-01, 7.0485e-01]]],\n",
            "\n",
            "\n",
            "          [[[5.8015e-01, 7.6424e-01, 2.5119e-01, 8.8418e-01],\n",
            "            [1.7943e-01, 2.8721e-01, 6.4228e-02, 7.6908e-01],\n",
            "            [2.0805e-01, 9.5915e-01, 9.3598e-01, 9.5323e-01],\n",
            "            [3.7928e-01, 4.9253e-01, 4.8387e-01, 5.4833e-01]],\n",
            "\n",
            "           [[5.9213e-01, 7.2086e-01, 4.5739e-01, 4.5792e-01],\n",
            "            [2.2265e-01, 5.2966e-01, 4.6030e-01, 9.5269e-01],\n",
            "            [4.3458e-01, 1.4386e-01, 1.5352e-01, 8.3753e-01],\n",
            "            [7.1899e-01, 3.3962e-01, 3.1829e-05, 6.9245e-01]],\n",
            "\n",
            "           [[3.9963e-01, 5.3041e-01, 3.0805e-01, 5.9012e-01],\n",
            "            [7.0054e-01, 5.5700e-01, 1.3914e-01, 4.2234e-01],\n",
            "            [2.5089e-01, 2.4460e-01, 4.5050e-01, 8.6132e-01],\n",
            "            [7.2481e-01, 6.1727e-03, 7.5898e-02, 3.4437e-01]],\n",
            "\n",
            "           [[2.2053e-01, 3.1767e-01, 5.0666e-01, 3.1909e-01],\n",
            "            [1.5084e-01, 4.0104e-01, 6.4741e-01, 6.8497e-01],\n",
            "            [6.2270e-01, 6.8573e-03, 3.3469e-01, 9.1387e-01],\n",
            "            [1.3210e-01, 7.3397e-01, 1.9899e-01, 4.6350e-01]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[8.3083e-02, 3.0082e-01, 7.7207e-01, 7.3871e-01],\n",
            "            [3.3457e-01, 2.8575e-01, 2.7343e-01, 8.3768e-01],\n",
            "            [9.8232e-01, 3.7361e-01, 5.9171e-01, 1.6792e-01],\n",
            "            [3.3130e-01, 4.6843e-01, 3.4851e-01, 7.4090e-01]],\n",
            "\n",
            "           [[4.3311e-01, 7.6890e-01, 5.8960e-01, 8.1048e-01],\n",
            "            [1.0736e-01, 2.4125e-03, 5.0246e-01, 5.9908e-01],\n",
            "            [7.8102e-01, 9.3186e-01, 7.2754e-01, 6.2892e-01],\n",
            "            [6.6651e-01, 4.7026e-01, 3.2028e-01, 6.8491e-01]],\n",
            "\n",
            "           [[6.6458e-01, 5.1829e-01, 3.5684e-01, 4.8835e-01],\n",
            "            [9.4437e-01, 4.3659e-01, 7.3710e-01, 1.0054e-01],\n",
            "            [3.3276e-02, 7.1691e-01, 9.5096e-01, 2.1225e-02],\n",
            "            [7.7069e-01, 9.1081e-01, 5.2285e-01, 7.4272e-01]],\n",
            "\n",
            "           [[5.0578e-03, 4.4227e-01, 8.0025e-01, 5.6609e-01],\n",
            "            [7.8755e-01, 1.2177e-01, 2.0332e-01, 8.2272e-01],\n",
            "            [4.4426e-01, 3.9598e-01, 9.7693e-01, 2.4276e-01],\n",
            "            [5.2707e-01, 1.2436e-01, 1.9854e-02, 1.8292e-01]]],\n",
            "\n",
            "\n",
            "          [[[8.9961e-01, 4.7383e-01, 8.5570e-02, 9.1276e-01],\n",
            "            [8.9534e-01, 4.3118e-02, 7.8137e-01, 8.0820e-01],\n",
            "            [9.6610e-01, 6.9946e-01, 4.3547e-01, 3.0553e-01],\n",
            "            [2.7306e-01, 8.1155e-01, 8.2116e-02, 9.2640e-01]],\n",
            "\n",
            "           [[1.4615e-01, 8.7510e-02, 6.3726e-02, 4.4800e-01],\n",
            "            [4.4567e-01, 4.0293e-01, 3.0219e-01, 3.5363e-01],\n",
            "            [5.9592e-02, 2.6398e-01, 9.0231e-01, 4.2637e-01],\n",
            "            [8.3676e-01, 5.5954e-01, 3.5128e-01, 8.1588e-01]],\n",
            "\n",
            "           [[2.6093e-01, 3.5660e-01, 4.5906e-03, 6.0552e-01],\n",
            "            [1.9749e-01, 9.1857e-01, 1.1674e-01, 9.5905e-01],\n",
            "            [2.2287e-01, 5.5386e-01, 9.4023e-01, 7.0456e-01],\n",
            "            [9.7401e-01, 4.0393e-01, 6.7069e-01, 7.0269e-01]],\n",
            "\n",
            "           [[3.1589e-01, 9.7855e-01, 4.0681e-02, 5.2715e-01],\n",
            "            [9.1474e-01, 6.9765e-01, 2.5878e-01, 5.1174e-01],\n",
            "            [7.3690e-01, 9.3278e-01, 3.3872e-01, 4.8221e-01],\n",
            "            [4.0273e-01, 9.4622e-01, 4.8297e-01, 6.1675e-02]]]]]]), tensor([[[[[[0.6380, 0.6380, 0.6380, 0.6380],\n",
            "            [0.4935, 0.4935, 0.4935, 0.4935],\n",
            "            [0.3643, 0.3643, 0.3643, 0.3643],\n",
            "            [0.9226, 0.9226, 0.9226, 0.9226]],\n",
            "\n",
            "           [[0.6380, 0.6380, 0.6380, 0.6380],\n",
            "            [0.4935, 0.4935, 0.4935, 0.4935],\n",
            "            [0.3643, 0.3643, 0.3643, 0.3643],\n",
            "            [0.9226, 0.9226, 0.9226, 0.9226]],\n",
            "\n",
            "           [[0.6380, 0.6380, 0.6380, 0.6380],\n",
            "            [0.4935, 0.4935, 0.4935, 0.4935],\n",
            "            [0.3643, 0.3643, 0.3643, 0.3643],\n",
            "            [0.9226, 0.9226, 0.9226, 0.9226]],\n",
            "\n",
            "           [[0.6380, 0.6380, 0.6380, 0.6380],\n",
            "            [0.4935, 0.4935, 0.4935, 0.4935],\n",
            "            [0.3643, 0.3643, 0.3643, 0.3643],\n",
            "            [0.9226, 0.9226, 0.9226, 0.9226]]],\n",
            "\n",
            "\n",
            "          [[[0.1880, 0.1880, 0.1880, 0.1880],\n",
            "            [0.4415, 0.4415, 0.4415, 0.4415],\n",
            "            [0.3922, 0.3922, 0.3922, 0.3922],\n",
            "            [0.8518, 0.8518, 0.8518, 0.8518]],\n",
            "\n",
            "           [[0.1880, 0.1880, 0.1880, 0.1880],\n",
            "            [0.4415, 0.4415, 0.4415, 0.4415],\n",
            "            [0.3922, 0.3922, 0.3922, 0.3922],\n",
            "            [0.8518, 0.8518, 0.8518, 0.8518]],\n",
            "\n",
            "           [[0.1880, 0.1880, 0.1880, 0.1880],\n",
            "            [0.4415, 0.4415, 0.4415, 0.4415],\n",
            "            [0.3922, 0.3922, 0.3922, 0.3922],\n",
            "            [0.8518, 0.8518, 0.8518, 0.8518]],\n",
            "\n",
            "           [[0.1880, 0.1880, 0.1880, 0.1880],\n",
            "            [0.4415, 0.4415, 0.4415, 0.4415],\n",
            "            [0.3922, 0.3922, 0.3922, 0.3922],\n",
            "            [0.8518, 0.8518, 0.8518, 0.8518]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0.9025, 0.9025, 0.9025, 0.9025],\n",
            "            [0.1892, 0.1892, 0.1892, 0.1892],\n",
            "            [0.7895, 0.7895, 0.7895, 0.7895],\n",
            "            [0.9392, 0.9392, 0.9392, 0.9392]],\n",
            "\n",
            "           [[0.9025, 0.9025, 0.9025, 0.9025],\n",
            "            [0.1892, 0.1892, 0.1892, 0.1892],\n",
            "            [0.7895, 0.7895, 0.7895, 0.7895],\n",
            "            [0.9392, 0.9392, 0.9392, 0.9392]],\n",
            "\n",
            "           [[0.9025, 0.9025, 0.9025, 0.9025],\n",
            "            [0.1892, 0.1892, 0.1892, 0.1892],\n",
            "            [0.7895, 0.7895, 0.7895, 0.7895],\n",
            "            [0.9392, 0.9392, 0.9392, 0.9392]],\n",
            "\n",
            "           [[0.9025, 0.9025, 0.9025, 0.9025],\n",
            "            [0.1892, 0.1892, 0.1892, 0.1892],\n",
            "            [0.7895, 0.7895, 0.7895, 0.7895],\n",
            "            [0.9392, 0.9392, 0.9392, 0.9392]]],\n",
            "\n",
            "\n",
            "          [[[0.6707, 0.6707, 0.6707, 0.6707],\n",
            "            [0.0878, 0.0878, 0.0878, 0.0878],\n",
            "            [0.3023, 0.3023, 0.3023, 0.3023],\n",
            "            [0.0477, 0.0477, 0.0477, 0.0477]],\n",
            "\n",
            "           [[0.6707, 0.6707, 0.6707, 0.6707],\n",
            "            [0.0878, 0.0878, 0.0878, 0.0878],\n",
            "            [0.3023, 0.3023, 0.3023, 0.3023],\n",
            "            [0.0477, 0.0477, 0.0477, 0.0477]],\n",
            "\n",
            "           [[0.6707, 0.6707, 0.6707, 0.6707],\n",
            "            [0.0878, 0.0878, 0.0878, 0.0878],\n",
            "            [0.3023, 0.3023, 0.3023, 0.3023],\n",
            "            [0.0477, 0.0477, 0.0477, 0.0477]],\n",
            "\n",
            "           [[0.6707, 0.6707, 0.6707, 0.6707],\n",
            "            [0.0878, 0.0878, 0.0878, 0.0878],\n",
            "            [0.3023, 0.3023, 0.3023, 0.3023],\n",
            "            [0.0477, 0.0477, 0.0477, 0.0477]]]],\n",
            "\n",
            "\n",
            "\n",
            "         [[[[0.0020, 0.0020, 0.0020, 0.0020],\n",
            "            [0.8567, 0.8567, 0.8567, 0.8567],\n",
            "            [0.3736, 0.3736, 0.3736, 0.3736],\n",
            "            [0.8432, 0.8432, 0.8432, 0.8432]],\n",
            "\n",
            "           [[0.0020, 0.0020, 0.0020, 0.0020],\n",
            "            [0.8567, 0.8567, 0.8567, 0.8567],\n",
            "            [0.3736, 0.3736, 0.3736, 0.3736],\n",
            "            [0.8432, 0.8432, 0.8432, 0.8432]],\n",
            "\n",
            "           [[0.0020, 0.0020, 0.0020, 0.0020],\n",
            "            [0.8567, 0.8567, 0.8567, 0.8567],\n",
            "            [0.3736, 0.3736, 0.3736, 0.3736],\n",
            "            [0.8432, 0.8432, 0.8432, 0.8432]],\n",
            "\n",
            "           [[0.0020, 0.0020, 0.0020, 0.0020],\n",
            "            [0.8567, 0.8567, 0.8567, 0.8567],\n",
            "            [0.3736, 0.3736, 0.3736, 0.3736],\n",
            "            [0.8432, 0.8432, 0.8432, 0.8432]]],\n",
            "\n",
            "\n",
            "          [[[0.8777, 0.8777, 0.8777, 0.8777],\n",
            "            [0.8050, 0.8050, 0.8050, 0.8050],\n",
            "            [0.9768, 0.9768, 0.9768, 0.9768],\n",
            "            [0.7433, 0.7433, 0.7433, 0.7433]],\n",
            "\n",
            "           [[0.8777, 0.8777, 0.8777, 0.8777],\n",
            "            [0.8050, 0.8050, 0.8050, 0.8050],\n",
            "            [0.9768, 0.9768, 0.9768, 0.9768],\n",
            "            [0.7433, 0.7433, 0.7433, 0.7433]],\n",
            "\n",
            "           [[0.8777, 0.8777, 0.8777, 0.8777],\n",
            "            [0.8050, 0.8050, 0.8050, 0.8050],\n",
            "            [0.9768, 0.9768, 0.9768, 0.9768],\n",
            "            [0.7433, 0.7433, 0.7433, 0.7433]],\n",
            "\n",
            "           [[0.8777, 0.8777, 0.8777, 0.8777],\n",
            "            [0.8050, 0.8050, 0.8050, 0.8050],\n",
            "            [0.9768, 0.9768, 0.9768, 0.9768],\n",
            "            [0.7433, 0.7433, 0.7433, 0.7433]]]]]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wd8Hy5iw15R9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}